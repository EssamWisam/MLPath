{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from mlpath import mlquest as mlq\n",
    "import numpy as np\n",
    "sys.path.append('../../')\n",
    "from DataPreparation.Ingestion.Ingestion import read_data\n",
    "from DataPreparation.Preprocessing.Preprocessing import preprocess_data, deep_data_loader\n",
    "from ModelImplementation.CNN.CNN import ConvNet, train_model, validate_model, save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlq.start_quest('CNN', table_dest='../../')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 202.64it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 107.08it/s]\n",
      "../../DataPreparation/Ingestion/Ingestion.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_data,  y_data = np.array(x_data), np.array(y_data)\n"
     ]
    }
   ],
   "source": [
    "x_train_i, x_val_i, y_train_i, y_val_i = read_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1, 400, 400)\n",
      "torch.Size([2, 1, 400, 400])\n",
      "(2, 1, 400, 400)\n",
      "torch.Size([2, 1, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "x_train_p, x_val_p = preprocess_data(x_train_i, x_val_i)\n",
    "train_loader, val_loader = deep_data_loader(x_train_p, y_train_i, x_val_p, y_val_i, batch_size=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = mlq.l(ConvNet)(hidden_size=80, output_size=2, kernel_dim = 10, in_channels=1, mid_channels=12, out_channels=16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = mlq.l(torch.optim.Adam)(model.parameters(), lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.25s/it]\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.35s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.67s/it]\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.51s/it]\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "mlq.l(train_model)(model, 12, train_loader, loss, optimizer, 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy is at 0.0 and Random Guessing Accuracy is at 50.0 %\n"
     ]
    }
   ],
   "source": [
    "accuracy, rand_accurary = validate_model(model, val_loader, 'cpu')\n",
    "mlq.log_metrics(accuracy, rand_accurary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlq.end_quest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
